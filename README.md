# ü§ñ RAG Chatbot with LINE Integration on macOS

- ‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏• `llama3:latest` ‡∏à‡∏≤‡∏Å Ollama (Local LLM)
- ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å Markdown/PDF (RAG)
- ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡πÅ‡∏•‡∏∞‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©
- ‡∏ï‡∏≠‡∏ö‡∏Å‡∏•‡∏±‡∏ö‡∏ú‡πà‡∏≤‡∏ô LINE Messaging API
- ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏î‡πâ‡∏ß‡∏¢ FastAPI ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ‡∏ö‡∏ô macOS


---
## ‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á Project 
### 1. ‡∏™‡∏£‡πâ‡∏≤‡∏á Folder Project ‡πÑ‡∏ß‡πâ‡∏ó‡∏µ‡πà‡∏™‡∏∞‡∏î‡∏ß‡∏Å ‡πÇ‡∏î‡∏¢‡∏°‡∏µ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÉ‡∏ô Visual studio Code ‡∏î‡∏±‡∏á‡∏ô‡∏µ‡πâ
-  chatbot-project/
    ‚îú‚îÄ‚îÄ appsmez                     # ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó
    ‚îú‚îÄ‚îÄ fooddee                     # ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó
    ‚îú‚îÄ‚îÄ scspark                     # ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó
    ‚îú‚îÄ‚îÄ app.py                      # FastAPI main server
    ‚îú‚îÄ‚îÄ ollama_client.py            # ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏Å‡∏±‡∏ö Ollama ‡πÅ‡∏•‡∏∞‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏• llama3
    ‚îú‚îÄ‚îÄ RAG_pipeline.py             # ‡∏£‡∏∞‡∏ö‡∏ö‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÅ‡∏•‡∏∞‡∏™‡∏Å‡∏±‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (RAG)
    ‚îú‚îÄ‚îÄ embedder.py                 # ‡πÇ‡∏°‡∏î‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ù‡∏±‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (embedding)
    ‚îú‚îÄ‚îÄ requirements.txt            # ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ dependencies
    ‚îú‚îÄ‚îÄ static/
    ‚îÇ   ‚îî‚îÄ‚îÄ script.js               # JavaScript ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö UI
    ‚îú‚îÄ‚îÄ templates/
        ‚îî‚îÄ‚îÄ index.html              # HTML Template ‡∏´‡∏•‡∏±‡∏Å
    ‚îú‚îÄ‚îÄ .env  
### 2. ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡∏≠‡∏á‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó
-  https://drive.google.com/drive/u/1/folders/1yBW0ueM-o9sXi4EGdyuPirJ8_4SFCC4F?usp=sharing

### 3. ‡∏™‡∏£‡πâ‡∏≤‡∏á Virtual Environment ‡πÅ‡∏•‡∏∞‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡πÑ‡∏•‡∏ö‡∏£‡∏≤‡∏£‡∏µ
```bash
python3 -m venv venv
source venv/bin/activate
```
### 4. ‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏ô‡∏≥ Code ‡πÑ‡∏õ‡πÉ‡∏™‡πà‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞ File 
-  Code ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö **"requirements.txt"**
```annotated-types==0.7.0
anyio==4.9.0
certifi==2025.4.26
click==8.2.1
colorama==0.4.6
fastapi==0.115.12
h11==0.16.0
httpcore==1.0.9
httpx==0.28.1
idna==3.10
Jinja2==3.1.6
joblib==1.5.0
langdetect==1.0.9
MarkupSafe==3.0.2
numpy==2.2.6
ollama==0.4.8
pydantic==2.11.4
pydantic_core==2.33.2
python-multipart==0.0.20
scikit-learn==1.6.1
scipy==1.15.3
six==1.17.0
sniffio==1.3.1
starlette==0.46.2
threadpoolctl==3.6.0
typing-inspection==0.4.1
typing_extensions==4.13.2
uvicorn==0.34.2
line-bot-sdk
langchain
langchain-community
langchain-ollama
pandas
python-multipart
openpyxl
```
-  Code ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö **" app.py "**
```bash
from linebot import LineBotApi, WebhookHandler
from linebot.exceptions import InvalidSignatureError
from linebot.models import MessageEvent, TextMessage, TextSendMessage

import os, re, uuid, logging, csv
import hashlib, hmac, json

from fastapi import FastAPI, Request, Form, Header
from fastapi.responses import JSONResponse, FileResponse
from fastapi.staticfiles import StaticFiles
from fastapi.templating import Jinja2Templates

from langdetect import detect
from ollama import Client

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

import pandas as pd
from openpyxl import Workbook

# Logging
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
    handlers=[
        logging.FileHandler("server.log", encoding="utf-8"),
        logging.StreamHandler()
    ]
)

# App setup
app = FastAPI()
templates = Jinja2Templates(directory="templates")
os.makedirs("exports", exist_ok=True)
os.makedirs("static", exist_ok=True)
app.mount("/static", StaticFiles(directory="static"), name="static")
app.mount("/exports", StaticFiles(directory="exports"), name="exports")
ollama_client = Client(host="http://localhost:11434")
session_chat_history = {}

# LINE setup
LINE_CHANNEL_ACCESS_TOKEN = os.getenv("LINE_CHANNEL_ACCESS_TOKEN")
LINE_CHANNEL_SECRET = os.getenv("LINE_CHANNEL_SECRET")
line_bot_api = LineBotApi(LINE_CHANNEL_ACCESS_TOKEN)
handler = WebhookHandler(LINE_CHANNEL_SECRET)

CSV_LOG_FILE = "conversation_history.csv"

# ------------------------------ CSV Logging ------------------------------
def remove_emoji(text):
    emoji_pattern = re.compile("["
        u"\U0001F600-\U0001F64F"
        u"\U0001F300-\U0001F5FF"
        u"\U0001F680-\U0001F6FF"
        u"\U0001F1E0-\U0001F1FF"
        u"\u2600-\u26FF"
        u"\u2700-\u27BF"
        "]+", flags=re.UNICODE)
    return emoji_pattern.sub(r'', str(text))

def log_to_csv(source, user_message, bot_reply):
    user_message = remove_emoji(user_message)
    bot_reply = remove_emoji(bot_reply)
    with open(CSV_LOG_FILE, mode='a', newline='', encoding='utf-8') as file:
        writer = csv.writer(file)
        writer.writerow([source, user_message, bot_reply])

# ------------------------------ Export to Excel ------------------------------
def export_conversation_to_excel():
    if not os.path.exists(CSV_LOG_FILE):
        return {"error": "CSV file not found"}

    df = pd.read_csv(CSV_LOG_FILE, names=["Source", "User Message", "Bot Reply"])
    df["User Message"] = df["User Message"].apply(remove_emoji)
    df["Bot Reply"] = df["Bot Reply"].apply(remove_emoji)

    file_path = "exports/conversation_export.xlsx"

    with pd.ExcelWriter(file_path, engine="openpyxl") as writer:
        df.to_excel(writer, index=False, sheet_name="All_Conversations")
        df.tail(50).to_excel(writer, index=False, sheet_name="Recent_50")
        df[df["Source"] == "line"].to_excel(writer, index=False, sheet_name="Source_line")
        df[df["Source"] == "web"].to_excel(writer, index=False, sheet_name="Source_web")
        for lang in ["th", "en"]:
            filtered = df[df["User Message"].apply(lambda x: detect(x) == lang)]
            if not filtered.empty:
                filtered.to_excel(writer, index=False, sheet_name=f"Language_{lang}")

    return {"message": f"Exported to Excel: {file_path}"}

# ------------------------------ Markdown Knowledge Base ------------------------------
def load_markdown_knowledge():
    md_directories = ["appsmez", "fooddee", "scspark"]
    combined_text = ""
    for md_dir in md_directories:
        if os.path.exists(md_dir):
            for root, _, files in os.walk(md_dir):
                for filename in files:
                    if filename.endswith(".md"):
                        filepath = os.path.join(root, filename)
                        try:
                            with open(filepath, encoding="utf-8") as f:
                                combined_text += f"\n{f.read()}\n"
                        except Exception as e:
                            logging.error(f"Error loading {filepath}: {e}")
    return combined_text.strip() if combined_text else "‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö"

def extract_markdown_sections(text):
    pattern = r"^#+\s.+"
    lines = text.split('\n')
    sections, current_section = [], []
    for line in lines:
        if re.match(pattern, line):
            if current_section:
                sections.append('\n'.join(current_section).strip())
            current_section = [line]
        else:
            current_section.append(line)
    if current_section:
        sections.append('\n'.join(current_section).strip())
    return [s for s in sections if len(s.split('\n')) > 1]

knowledge_context = load_markdown_knowledge()
knowledge_chunks = extract_markdown_sections(knowledge_context)
vectorizer = TfidfVectorizer().fit(knowledge_chunks)
knowledge_vectors = vectorizer.transform(knowledge_chunks)

def retrieve_relevant_chunks(question, top_k=5):
    if knowledge_context == "‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö":
        return ""
    question_vec = vectorizer.transform([question])
    similarities = cosine_similarity(question_vec, knowledge_vectors).flatten()
    top_indices = similarities.argsort()[-top_k:][::-1]
    return "\n\n".join(
        knowledge_chunks[i].strip()
        for i in top_indices if similarities[i] > 0
    )

def build_prompts(message, relevant_context, user_lang):
    language_instruction = "‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏≠‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢" if user_lang == "th" else "Please answer in English"
    system_content = f"""
‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡πÅ‡∏ä‡∏ó‡∏ö‡∏≠‡∏ó‡∏Ç‡∏≠‡∏á‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó ‡∏ó‡∏µ‡πà‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÇ‡∏î‡∏¢‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏à‡∏≤‡∏Å‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£ Markdown ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô ‡∏´‡πâ‡∏≤‡∏°‡πÅ‡∏ï‡πà‡∏á‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏î‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
‡∏´‡∏≤‡∏Å‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ‡πÉ‡∏´‡πâ‡∏ï‡∏≠‡∏ö‡∏ß‡πà‡∏≤ \"‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ñ‡∏≤‡∏°\"
‡πÉ‡∏´‡πâ‡∏ï‡∏≠‡∏ö‡∏Å‡∏•‡∏±‡∏ö‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ‡∏†‡∏≤‡∏©‡∏≤‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏° (‡πÑ‡∏ó‡∏¢‡∏ï‡∏≠‡∏ö‡πÑ‡∏ó‡∏¢, ‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©‡∏ï‡∏≠‡∏ö‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©)
‡∏´‡πâ‡∏≤‡∏°‡πÉ‡∏ä‡πâ‡∏Ñ‡∏≥‡∏ß‡πà‡∏≤ \"‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ç‡πâ‡∏≤‡∏á‡∏ï‡πâ‡∏ô\" \"‡∏à‡∏≤‡∏Å‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£\" \"‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå\"
‡πÉ‡∏´‡πâ‡∏ï‡∏≠‡∏ö‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏ï‡∏≤‡∏° Markdown ‡∏à‡∏£‡∏¥‡∏á ‡πÄ‡∏ä‡πà‡∏ô ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£ ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î ‡∏Ø‡∏•‡∏Ø
‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏ï‡πâ‡∏≠‡∏á:
- ‡πÅ‡∏™‡∏î‡∏á‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏´‡∏•‡∏±‡∏Å (‡πÄ‡∏ä‡πà‡∏ô `#`) ‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á
- ‡πÅ‡∏™‡∏î‡∏á‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏¢‡πà‡∏≠‡∏¢ (`##`, `###`) ‡πÅ‡∏•‡∏∞‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
- ‡∏´‡πâ‡∏≤‡∏°‡∏™‡∏£‡∏∏‡∏õ ‡∏´‡πâ‡∏≤‡∏°‡∏ï‡∏±‡∏î‡∏ó‡∏≠‡∏ô
{language_instruction}
"""
    user_content = f"""
‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ‡∏Ñ‡∏∑‡∏≠‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≤‡∏Å‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£ Markdown ‡∏Ç‡∏≠‡∏á‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó:

{relevant_context}

‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏ñ‡∏≤‡∏°‡∏ß‡πà‡∏≤:
{message}

**‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏≠‡∏ö‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ç‡πâ‡∏≤‡∏á‡∏ï‡πâ‡∏ô‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô**
- ‡πÉ‡∏´‡πâ‡∏ï‡∏≠‡∏ö‡πÇ‡∏î‡∏¢‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤ ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà‡πÅ‡∏Ñ‡πà‡∏ä‡∏∑‡πà‡∏≠‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠
- ‡∏ñ‡πâ‡∏≤‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏°‡∏µ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤ ‡πÉ‡∏´‡πâ‡πÅ‡∏™‡∏î‡∏á‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏ô‡∏±‡πâ‡∏ô
- ‡∏´‡πâ‡∏≤‡∏°‡∏ï‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÑ‡∏°‡πà‡∏£‡∏π‡πâ ‡πÄ‡∏ß‡πâ‡∏ô‡πÅ‡∏ï‡πà‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏à‡∏£‡∏¥‡∏á ‡πÜ
- ‡∏´‡πâ‡∏≤‡∏°‡πÄ‡∏ï‡∏¥‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÉ‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ç‡πâ‡∏≤‡∏á‡∏ï‡πâ‡∏ô
"""
    return system_content, user_content

# ------------------------------ Endpoints ------------------------------
def save_to_csv(session_id, user_message, bot_reply, context="", question_type="", confidence=0.0):
    csv_file = "conversation_history.csv"
    file_exists = os.path.exists(csv_file)

    try:
        with open(csv_file, 'a', newline='', encoding='utf-8') as file:
            writer = csv.writer(file, quoting=csv.QUOTE_ALL)

            # ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô header ‡∏ñ‡πâ‡∏≤‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏´‡∏°‡πà
            if not file_exists:
                writer.writerow([
                    'timestamp',
                    'session_id',
                    'user_message',
                    'bot_reply',
                    'context',
                    'question_type',
                    'confidence',
                    'user_language'
                ])

            timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            writer.writerow([
                timestamp,
                session_id,
                user_message,
                bot_reply,
                context[:500],
                question_type,
                confidence,
                "th"
            ])
        logging.info("[CSV] Test data saved")
    except Exception as e:
        logging.error(f"[CSV] Error: {e}")

# ---------- ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏£‡πâ‡∏≤‡∏á Excel ----------
def save_to_excel():
    csv_file = "conversation_history.csv"
    excel_file = "conversation_history.xlsx"

    if not os.path.exists(csv_file):
        logging.warning("[Excel] CSV file not found")
        return False

    try:
        df = pd.read_csv(csv_file, encoding='utf-8')
        if df.empty:
            logging.warning("[Excel] CSV has no data")
            return False

        df['timestamp'] = pd.to_datetime(df['timestamp'])

        with pd.ExcelWriter(excel_file, engine='openpyxl') as writer:
            df.to_excel(writer, sheet_name='All_Conversations', index=False)
            df.tail(50).to_excel(writer, sheet_name='Recent_50', index=False)

        logging.info("[Excel] Excel saved")
        return True
    except Exception as e:
        logging.error(f"[Excel] Error: {e}")
        return False

# ---------- ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÅ‡∏•‡∏∞‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á ----------
def ensure_test_data_exists():
    csv_file = "conversation_history.csv"
    if not os.path.exists(csv_file) or os.stat(csv_file).st_size < 100:
        logging.info("[Data] Adding test row...")
        save_to_csv(
            session_id="test_session",
            user_message="‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ",
            bot_reply="‡∏¢‡∏¥‡∏ô‡∏î‡∏µ‡∏ï‡πâ‡∏≠‡∏ô‡∏£‡∏±‡∏ö",
            context="## ‡πÅ‡∏ä‡∏ó‡∏ö‡∏≠‡∏ó\n‡∏¢‡∏¥‡∏ô‡∏î‡∏µ‡∏ä‡πà‡∏ß‡∏¢‡πÄ‡∏´‡∏•‡∏∑‡∏≠",
            question_type="rag",
            confidence=1.0
        )

# ---------- Startup Event ----------
@app.on_event("startup")
async def startup_event():
    logging.info("üöÄ Starting server...")
    ensure_test_data_exists()
    if os.path.exists("conversation_history.csv"):
        logging.info("‚úÖ Generating Excel from CSV...")
        success = save_to_excel()
        if success:
            logging.info("‚úÖ Excel generated")
        else:
            logging.warning("‚ö†Ô∏è Excel generation failed")

# ---------- Endpoint: ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î Excel ----------
@app.get("/download-excel")
async def download_excel():
    excel_file = "conversation_history.xlsx"

    if not os.path.exists(excel_file):
        logging.info("[Excel] Excel file not found, generating...")
        ensure_test_data_exists()
        success = save_to_excel()
        if not success:
            return JSONResponse(content={
                "error": "‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå Excel ‡πÑ‡∏î‡πâ ‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡πà‡∏≠‡∏ô"
            }, status_code=404)

    try:
        with open(excel_file, 'rb') as file:
            content = file.read()

        return Response(
            content=content,
            media_type="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            headers={"Content-Disposition": f"attachment; filename={excel_file}"}
        )
    except Exception as e:
        logging.error(f"[Excel] Download error: {e}")
        return JSONResponse(content={"error": "‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏Ç‡∏ì‡∏∞‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå Excel"}, status_code=500)

# ---------- Quick Test ----------
@app.get("/quick-test")
async def quick_test():
    return {"message": "Quick test successful"}

@app.get("/export-excel")
async def export_excel():
    """‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏•‡∏∞‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î Excel ‡πÉ‡∏ô endpoint ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß"""
    ensure_test_data_exists()
    success = save_to_excel()
    
    if not success:
        return JSONResponse(content={
            "error": "‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå Excel ‡πÑ‡∏î‡πâ ‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö"
        }, status_code=500)

    try:
        with open("conversation_history.xlsx", "rb") as f:
            content = f.read()
        return Response(
            content=content,
            media_type="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            headers={"Content-Disposition": "attachment; filename=conversation_history.xlsx"}
        )
    except Exception as e:
        logging.error(f"[Excel] Export error: {e}")
        return JSONResponse(content={"error": "‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î"}, status_code=500)

```

-  Code ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö **"ollama_client.py"**
```bash
import requests

class OllamaClient:
    def __init__(self, host="http://localhost:11434"):
        self.host = host

    def chat(self, model, messages):
        response = requests.post(
            f"{self.host}/api/chat",
            json={"model": model, "messages": messages}
        )
        return response.json()

ollama_client = OllamaClient()

```

-  Code ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö **"RAG_pipeline.py"**
```bash
import os
import re
import requests
import logging
import json
from bs4 import BeautifulSoup
from langchain_core.documents import Document
from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain.chains import RetrievalQA
from langchain_community.chat_models import ChatOpenAI
from langchain.prompts import PromptTemplate

logging.basicConfig(level=logging.INFO)

# üîπ ‡∏•‡∏¥‡∏™‡∏ï‡πå‡πÄ‡∏ß‡πá‡∏ö‡πÑ‡∏ã‡∏ï‡πå‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
URLS = [
    "https://appsmez.com/",
    "https://appsmez.com/compare",
    "https://appsmez.com/booking-app",
    "https://appsmez.com/shopping-app",
    "https://appsmez.com/delivery-app",
    "https://appsmez.com/ecommerce-delivery-app",
    "https://appsmez.com/express-app",
    "https://appsmez.com/food-ordering-app",
    "https://appsmez.com/hotel-booking-app",
    "https://appsmez.com/reward-point-app",
    "https://appsmez.com/elearning-app",
    "https://reviews.appsmez.com/appsmezblogs/",
    "https://reviews.appsmez.com/sme_review/",
    "https://fooddee.co/th/",
    "https://fooddee.co/th/franchise/",
    "https://fooddee.co/th/delivery/",
    "https://fooddee.co/th/travel/",
    "https://fooddee.co/th/taxi/",
    "https://www.sc-sparksolution.com/",
    "https://www.sc-sparksolution.com/sme-erp/",
    "https://www.sc-sparksolution.com/%e0%b8%a3%e0%b8%b1%e0%b8%9a%e0%b8%97%e0%b8%b3-mobile-application/",
    "https://www.sc-sparksolution.com/cms-smez-app/",
    "https://www.sc-sparksolution.com/digital-marketing/",
    "https://www.sc-sparksolution.com/promote-application/",
    "https://www.sc-sparksolution.com/google-ads/",
    "https://www.sc-sparksolution.com/facebook-ads/",
    "https://www.sc-sparksolution.com/youtube-ads/",
    "https://www.sc-sparksolution.com/content-marketing/",
    "https://www.sc-sparksolution.com/line-oa/",
    "https://www.sc-sparksolution.com/%e0%b8%a3%e0%b8%b1%e0%b8%9a%e0%b8%97%e0%b8%b3%e0%b9%80%e0%b8%a7%e0%b9%87%e0%b8%9a%e0%b9%84%e0%b8%8b%e0%b8%95%e0%b9%8c-e-commerce-%e0%b8%94%e0%b9%89%e0%b8%a7%e0%b8%a2-opencart/",
    "https://www.sc-sparksolution.com/%e0%b8%a3%e0%b8%b1%e0%b8%9a%e0%b8%97%e0%b8%b3%e0%b9%80%e0%b8%a7%e0%b9%87%e0%b8%9a%e0%b9%84%e0%b8%8b%e0%b8%95%e0%b9%8c-e-commerce-%e0%b9%81%e0%b8%a5%e0%b8%b0%e0%b8%ad%e0%b8%ad%e0%b8%81%e0%b9%81/",
    "https://www.sc-sparksolution.com/%e0%b8%a3%e0%b8%b1%e0%b8%9a%e0%b8%97%e0%b8%b3%e0%b9%80%e0%b8%a7%e0%b9%87%e0%b8%9a%e0%b9%84%e0%b8%8b%e0%b8%95%e0%b9%8c-responsive-design/",
    "https://www.sc-sparksolution.com/%e0%b8%a3%e0%b8%b1%e0%b8%9a%e0%b8%97%e0%b8%b3-seo-%e0%b8%94%e0%b9%89%e0%b8%a7%e0%b8%a2%e0%b9%80%e0%b8%97%e0%b8%84%e0%b8%99%e0%b8%b4%e0%b8%84%e0%b8%a1%e0%b8%b7%e0%b8%ad%e0%b8%ad%e0%b8%b2%e0%b8%8a/",
    "https://www.sc-sparksolution.com/%e0%b8%a3%e0%b8%b1%e0%b8%9a%e0%b8%97%e0%b8%b3-enterprise-java-application/",
    "https://www.sc-sparksolution.com/%e0%b8%9c%e0%b8%a5%e0%b8%87%e0%b8%b2%e0%b8%99%e0%b8%82%e0%b8%ad%e0%b8%87%e0%b9%80%e0%b8%a3%e0%b8%b2/",
    "https://www.sc-sparksolution.com/%e0%b8%a3%e0%b8%b2%e0%b8%84%e0%b8%b2%e0%b9%81%e0%b8%9e%e0%b8%84%e0%b9%80%e0%b8%81%e0%b8%88/"

]

# üîπ Web Scraper: ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏´‡∏ô‡πâ‡∏≤
def scrape_website(url):
    try:
        response = requests.get(url, timeout=10)
        soup = BeautifulSoup(response.text, "html.parser")

        # ‡∏î‡∏∂‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç
        texts = soup.stripped_strings
        page_text = "\n".join(texts)

        return page_text
    except Exception as e:
        print(f"‚ùå Error scraping {url}: {e}")
        return ""

# üîπ ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏à‡∏≤‡∏Å‡πÄ‡∏ß‡πá‡∏ö‡πÑ‡∏ã‡∏ï‡πå
def load_all_web_content():
    docs = []
    for url in URLS:
        content = scrape_website(url)
        if content:
            doc = Document(page_content=content, metadata={"source": url})
            docs.append(doc)
    logging.info(f"‚úÖ Total documents scraped: {len(docs)}")
    return docs

# üîπ ‡∏™‡∏£‡πâ‡∏≤‡∏á FAISS vectorstore
def build_vectorstore(docs, persist_path="faiss_index_web"):
    embeddings = HuggingFaceEmbeddings(
    model_name="sentence-transformers/all-MiniLM-L6-v2"
)
    vectorstore = FAISS.from_documents(docs, embeddings)
    vectorstore.save_local(persist_path)
    return vectorstore

# üîπ ‡∏™‡∏£‡πâ‡∏≤‡∏á QA chain
# def build_qa_chain(vectorstore):
#     prompt_template = PromptTemplate(
#         input_variables=["context", "question"],
#         template="""
# ‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢ AI ‡∏ó‡∏µ‡πà‡πÉ‡∏´‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÄ‡∏ß‡πá‡∏ö‡πÑ‡∏ã‡∏ï‡πå‡∏Ç‡∏≠‡∏á‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏™‡∏∏‡∏†‡∏≤‡∏û‡πÅ‡∏•‡∏∞‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô
# ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ‡∏Ñ‡∏∑‡∏≠‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á:

# {context}

# ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°: {question}
# ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏≠‡∏ö‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ‡∏†‡∏≤‡∏©‡∏≤‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏†‡∏≤‡∏û ‡πÅ‡∏•‡∏∞‡∏´‡∏≤‡∏Å‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏≠‡∏ö‡∏ß‡πà‡∏≤ '‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢ ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö'
# """
#     )

#     retriever = vectorstore.as_retriever(search_kwargs={"k": 3})
#     chain = RetrievalQA.from_chain_type(
#         llm=ChatOpenAI(model_name="gpt-4"),
#         retriever=retriever,
#         chain_type_kwargs={"prompt": prompt_template}
#     )
#     return chain

# # üîπ ‡∏•‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡πÉ‡∏´‡πâ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°
# def clean_answer(text):
#     text = re.sub(r'[^\u0E00-\u0E7F\s0-9,.!?()\-]', '', text)
#     text = re.sub(r'\s+', ' ', text).strip()
#     return text

# # üîπ ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ñ‡∏≤‡∏°-‡∏ï‡∏≠‡∏ö
# def ask(question):
#     docs = load_all_web_content()
#     vectorstore = build_vectorstore(docs)
#     qa = build_qa_chain(vectorstore)
#     raw_answer = qa.run(question)
#     return clean_answer(raw_answer)

def load_vectorstore(persist_path="faiss_index_web"):
    if not os.path.exists(persist_path):
        logging.warning("FAISS index not found, building new one...")
        docs = load_all_web_content()
        return build_vectorstore(docs, persist_path)
    embeddings = HuggingFaceEmbeddings(
    model_name="sentence-transformers/all-MiniLM-L6-v2"
)
    return FAISS.load_local(persist_path, embeddings)

def build_qa_chain(vectorstore):
    prompt_template = PromptTemplate(
        input_variables=["context", "question"],
        template="""
‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢ AI ‡∏Ç‡∏≠‡∏á‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó‡∏ó‡∏µ‡πà‡πÉ‡∏´‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÄ‡∏ß‡πá‡∏ö‡πÑ‡∏ã‡∏ï‡πå‡∏Ç‡∏≠‡∏á‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô
‡∏´‡πâ‡∏≤‡∏°‡πÅ‡∏ï‡πà‡∏á‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏î‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ‡∏´‡∏≤‡∏Å‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏£‡∏á ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏≠‡∏ö‡∏ß‡πà‡∏≤ '‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢ ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö'

‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ‡∏Ñ‡∏∑‡∏≠‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á:

{context}

‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°: {question}
‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏≠‡∏ö‡πÇ‡∏î‡∏¢‡∏™‡∏∏‡∏†‡∏≤‡∏û‡πÅ‡∏•‡∏∞‡πÉ‡∏ä‡πâ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏Ç‡πâ‡∏≤‡∏á‡∏ï‡πâ‡∏ô‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô
"""
    )
    retriever = vectorstore.as_retriever(search_kwargs={"k": 3})
    chain = RetrievalQA.from_chain_type(
        llm=ChatOpenAI(model_name="gpt-4", temperature=0),
        retriever=retriever,
        chain_type_kwargs={"prompt": prompt_template}
    )
    return chain

def clean_answer(text):
    text = re.sub(r'[^\u0E00-\u0E7F\s0-9,.!?()\-]', '', text)
    text = re.sub(r'\s+', ' ', text).strip()
    return text

def is_valid_question(question):
    """‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢ ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà spam ‡∏´‡∏£‡∏∑‡∏≠‡∏°‡∏±‡πà‡∏ß"""
    question = question.strip()

    # ‡∏õ‡∏è‡∏¥‡πÄ‡∏™‡∏ò‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏™‡∏±‡πâ‡∏ô‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ
    if len(question) < 5:
        return False

    # ‡∏õ‡∏è‡∏¥‡πÄ‡∏™‡∏ò‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£‡∏ã‡πâ‡∏≥ ‡πÄ‡∏ä‡πà‡∏ô '55555', 'aaaaa'
    if len(set(question)) <= 2:
        return False

    # ‡∏õ‡∏è‡∏¥‡πÄ‡∏™‡∏ò‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏•‡πâ‡∏ß‡∏ô ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£‡πÄ‡∏•‡∏¢
    if not re.search(r'[‡∏Å-‡πôa-zA-Z]', question):
        return False

    # ‡∏õ‡∏è‡∏¥‡πÄ‡∏™‡∏ò‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏±‡∏ç‡∏•‡∏±‡∏Å‡∏©‡∏ì‡πå‡∏û‡∏¥‡πÄ‡∏®‡∏©‡∏•‡πâ‡∏ß‡∏ô
    if re.fullmatch(r'[^\w\s]+', question):
        return False

    return True

def log_to_jsonl(question, answer, file_path="chat_training_data.jsonl"):
    data = {
        "prompt": question.strip(),
        "completion": answer.strip()
    }
    with open(file_path, "a", encoding="utf-8") as f:
        f.write(json.dumps(data, ensure_ascii=False) + "\n")

def ask(question):
    logging.info(f"[ASK] Question: {question}")

    if not is_valid_question(question):
        logging.warning("[ASK] Invalid or spam-like question. Skipping.")
        return "‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢ ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ñ‡∏≤‡∏°‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô‡πÅ‡∏•‡∏∞‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤‡∏ô‡∏µ‡πâ"

    vectorstore = load_vectorstore()
    qa = build_qa_chain(vectorstore)
    raw_answer = qa.run(question)
    final_answer = clean_answer(raw_answer)

    # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤
    if final_answer:
        log_to_jsonl(question, final_answer)
        logging.info(f"[ASK] Answer: {final_answer}")
        return final_answer
    else:
        logging.info("[ASK] No useful answer found.")
        return "‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢ ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö"

```

-  Code ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö **"embedder.py"**
```bash
import os
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from pathlib import Path

def load_documents_and_build_vectorizer():
    docs = []
    paths = []

    base_dirs = ["appSmez", "fooddee", "scspark"]
    for base in base_dirs:
        for md_file in Path(base).rglob("*.md"):
            content = md_file.read_text(encoding="utf-8")
            chunks = [content[i:i+300] for i in range(0, len(content), 300)]
            docs.extend(chunks)
            paths.extend([md_file.name] * len(chunks))

    vectorizer = TfidfVectorizer().fit(docs)
    vectors = vectorizer.transform(docs)
    return docs, vectors, vectorizer

def retrieve_relevant_chunks(question, docs, vectors, vectorizer, top_k=3):
    question = question.lower().strip()
    q_vec = vectorizer.transform([question])
    similarities = cosine_similarity(q_vec, vectors).flatten()
    top_indices = similarities.argsort()[-top_k:][::-1]
    relevant_texts = [docs[i].strip() for i in top_indices if similarities[i] > 0.1]

    return "\n\n".join([f"- {text}" for text in relevant_texts]) if relevant_texts else ""

```

-  Code ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö **"static => script.js "**
```bash
async function sendQuestion() {
  const input = document.getElementById("user-input");
  const question = input.value;
  input.value = "";

  const chatBox = document.getElementById("chat-box");
  chatBox.innerHTML += `<div class="user">‡∏Ñ‡∏∏‡∏ì: ${question}</div>`;

  const res = await fetch("/ask", {
    method: "POST",
    headers: { "Content-Type": "application/json" },
    body: JSON.stringify({ question })
  });

  const data = await res.json();
  chatBox.innerHTML += `<div class="bot">‡∏ö‡∏≠‡∏ó: ${data.answer}</div>`;
  chatBox.scrollTop = chatBox.scrollHeight;
}
```

-  Code ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö **"templates => index.html "**
```bash
<!DOCTYPE html>
<html lang="th">
<head>
    <meta charset="UTF-8" />
    <title>Chatbot</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            max-width: 700px;
            margin: 30px auto;
            padding: 10px;
            background-color: #f5f5f5;
        }
        .chat-container {
            border: 1px solid #ccc;
            padding: 15px;
            background: white;
            height: 500px;
            overflow-y: auto;
            display: flex;
            flex-direction: column;
            gap: 10px;
        }
        .message {
            max-width: 70%;
            padding: 8px 12px;
            border-radius: 12px;
            line-height: 1.3;
            word-wrap: break-word;
        }
        .user {
            align-self: flex-end;
            background-color: #cce5ff;
            text-align: right;
        }
        .bot {
            align-self: flex-start;
            background-color: #d4edda;
            text-align: left;
        }
        form {
            margin-top: 10px;
            display: flex;
            gap: 5px;
        }
        input[type=text] {
            flex: 1;
            padding: 8px;
            font-size: 1em;
        }
        button {
            padding: 8px 15px;
            font-size: 1em;
        }
    </style>
</head>
<body>
    <h1>Chatbot</h1>
    <div class="chat-container" id="chat-container"></div>

    <form id="chat-form">
        <input type="text" id="message-input" autocomplete="off" placeholder="‡∏û‡∏¥‡∏°‡∏û‡πå‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°..." required />
        <button type="submit">‡∏™‡πà‡∏á</button>
    </form>

    <script>
        const chatContainer = document.getElementById('chat-container');
        const form = document.getElementById('chat-form');
        const input = document.getElementById('message-input');

        async function loadMessages() {
            const res = await fetch('/messages');
            const data = await res.json();

            chatContainer.innerHTML = '';
            if (data.length === 0) {
                const botDiv = document.createElement('div');
                botDiv.className = 'message bot';
                botDiv.innerHTML = `<strong>‡∏ô‡πâ‡∏≥‡πÉ‡∏™ AI:</strong> ‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ ‡∏¢‡∏¥‡∏ô‡∏î‡∏µ‡πÉ‡∏´‡πâ‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£ ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏û‡∏¥‡∏°‡∏û‡πå‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡∏≠‡∏á‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó`;
                chatContainer.appendChild(botDiv);
            } else {
                data.forEach(msg => {
                    const div = document.createElement('div');
                    div.className = `message ${msg.sender}`;
                    div.innerHTML = `<strong>${msg.sender === 'user' ? '‡∏Ñ‡∏∏‡∏ì' : '‡∏ô‡πâ‡∏≥‡πÉ‡∏™ AI'}:</strong> ${msg.text}`;
                    chatContainer.appendChild(div);
                });
            }
            chatContainer.scrollTop = chatContainer.scrollHeight;
        }

        form.addEventListener('submit', async (e) => {
            e.preventDefault();
            const message = input.value.trim();
            if (!message) return;

            const userDiv = document.createElement('div');
            userDiv.className = 'message user';
            userDiv.innerHTML = `<strong>‡∏Ñ‡∏∏‡∏ì:</strong> ${message}`;
            chatContainer.appendChild(userDiv);
            chatContainer.scrollTop = chatContainer.scrollHeight;

            input.value = '';
            input.disabled = true;

            const res = await fetch('/chat', {
                method: 'POST',
                headers: { 'Content-Type': 'application/x-www-form-urlencoded' },
                body: `message=${encodeURIComponent(message)}`
            });
            const result = await res.json();

            const botDiv = document.createElement('div');
            botDiv.className = 'message bot';
            botDiv.innerHTML = `<strong>‡∏ô‡πâ‡∏≥‡πÉ‡∏™ AI:</strong> ${result.reply}`;
            chatContainer.appendChild(botDiv);
            chatContainer.scrollTop = chatContainer.scrollHeight;

            input.disabled = false;
            input.focus();
        });

        loadMessages();
    </script>
</body>
</html>

```

-  Code ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö **" .env "**
```bash
LINE_CHANNEL_ACCESS_TOKEN=       # "CHANNEL ACCESS TOKEN" ‡∏Ç‡∏≠‡∏á ChatLine ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì
LINE_CHANNEL_SECRET=             # "CHANNEL SECRET" ‡∏Ç‡∏≠‡∏á ChatLine ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì
```


### 5.‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á ngrok ‡πÅ‡∏•‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏Å‡∏±‡∏ö Line
1. ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á ngrok ‡∏ö‡∏ô macOS
‚úÖ ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà‡∏á‡πà‡∏≤‡∏¢‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î: ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡∏ú‡πà‡∏≤‡∏ô Homebrew
```bash
brew install --cask ngrok
```

‚úÖ ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ ngrok ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß:

```bash
ngrok version
```

2. ‡∏•‡∏á‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô‡∏ö‡∏±‡∏ç‡∏ä‡∏µ ngrok ‡πÅ‡∏•‡∏∞‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Token
‚û§ ‡πÑ‡∏õ‡∏ó‡∏µ‡πà: https://dashboard.ngrok.com/signup
‡∏™‡∏°‡∏±‡∏Ñ‡∏£‡πÅ‡∏•‡∏∞‡πÄ‡∏Ç‡πâ‡∏≤‡∏™‡∏π‡πà‡∏£‡∏∞‡∏ö‡∏ö ‡πÅ‡∏•‡πâ‡∏ß‡∏Ñ‡∏∏‡∏ì‡∏à‡∏∞‡πÑ‡∏î‡πâ Auth Token

‚û§ ‡∏à‡∏≤‡∏Å‡∏ô‡∏±‡πâ‡∏ô ‡∏£‡∏±‡∏ô‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡∏ô‡∏µ‡πâ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏° Token ‡∏Å‡∏±‡∏ö‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì:
```bash
ngrok config add-authtoken <your_token_here>
```
‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á:
```bash
ngrok config add-authtoken 2N8HxxxxxxYYYYzzzzzz
```

3. ‡∏™‡∏£‡πâ‡∏≤‡∏á Public URL ‡∏î‡πâ‡∏ß‡∏¢ ngrok
‡∏™‡∏°‡∏°‡∏ï‡∏¥‡∏ß‡πà‡∏≤ FastAPI ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡∏£‡∏±‡∏ô‡∏≠‡∏¢‡∏π‡πà‡∏ó‡∏µ‡πà localhost:8000 ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á:
```bash
ngrok http 8000
```
‡∏Ñ‡∏∏‡∏ì‡∏à‡∏∞‡πÑ‡∏î‡πâ URL ‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì‡∏ô‡∏µ‡πâ:
```bash
https://abc1234.ngrok.io
```

4. ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ LINE Messaging API
üìå ‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°:
LINE Developer Account ‚Üí https://developers.line.biz/

LINE Messaging API ‚Üí ‡∏™‡∏£‡πâ‡∏≤‡∏á Provider + Channel

Channel Access Token

Channel Secret

üìù ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Webhook
‡πÄ‡∏Ç‡πâ‡∏≤ LINE Developers Console

‡πÑ‡∏õ‡∏ó‡∏µ‡πà Project ‚Üí Messaging API

‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Webhook URL ‡πÄ‡∏õ‡πá‡∏ô:
```bash
https://abc1234.ngrok.io/webhook
```

‡πÄ‡∏õ‡∏¥‡∏î "Use Webhook" ‡πÄ‡∏õ‡πá‡∏ô ON

‡∏Å‡∏î "Verify" ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏•‡∏≠‡∏á‡∏¢‡∏¥‡∏á POST ‡πÑ‡∏õ‡∏ó‡∏µ‡πà /webhook ‡∏Ç‡∏≠‡∏á FastAPI




## ‡∏Å‡∏≤‡∏£ Run Project
### 1. ‡∏™‡∏£‡πâ‡∏≤‡∏á Virtual Environment ‡πÅ‡∏•‡∏∞‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡πÑ‡∏•‡∏ö‡∏£‡∏≤‡∏£‡∏µ
```bash
python3 -m venv venv
source venv/bin/activate
```
### 2. ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡πÑ‡∏•‡∏ö‡∏£‡∏≤‡∏£‡∏µ‡∏à‡∏≤‡∏Å requirements.txt
```bash
pip install -r requirements.txt
```
### 3. ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏•‡∏∞‡∏£‡∏±‡∏ô Ollama ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• llama3
‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á Ollama (‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô)
```bash
brew install ollama
```
‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• LLaMA3
```bash
ollama pull llama3:latest
```
‡∏£‡∏±‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏´‡πâ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏≠‡∏¢‡∏π‡πà‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏´‡∏•‡∏±‡∏á
```bash
ollama run llama3
```
### 4.Run Project
```bash
uvicorn app:app --reload
```
### 5. Run ngrok ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô URL
-  split terminal
```bash
ngrok http 8000 
```
‡∏à‡∏∞‡πÑ‡∏î‡πâ URL ‡∏°‡∏≤ ‡πÉ‡∏´‡πâ‡∏Ñ‡∏±‡∏î‡∏•‡∏≠‡∏Å‡∏ô‡∏≥‡πÑ‡∏õ‡πÉ‡∏™‡πà‡πÉ‡∏ô‡∏ä‡πà‡∏≠‡∏á Webhook ‡∏Ç‡∏≠‡∏á LINE Messaging API
‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á
```bash
https://abc1234.ngrok.io/webhook
```

# ‡∏ó‡∏î‡∏•‡∏≠‡∏á‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô Line Chatbot ‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢
